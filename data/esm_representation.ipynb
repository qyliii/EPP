{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d894ca55-74ae-49ec-b52e-2e38d42c6bf6",
   "metadata": {},
   "source": [
    "## **esm-2 representation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b437022-6e6c-47be-9340-5c4f2b275783",
   "metadata": {},
   "source": [
    "#### -- this doc aims to use the esm-2 model to represent the seq of antibodies & antigens, and train the Bi-LSTM model to learn the relationship between seq representations and the interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c6a466-c31b-4ba1-bf1c-1bc1e8586266",
   "metadata": {},
   "source": [
    "#### **1. loading the training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe66254-4b83-46a4-a40c-79d1b9bc408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cbef65f-a7e4-4216-9cc5-ab976873c147",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"./data/train.csv\"\n",
    "train_data = pd.read_csv(train_data_path,sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a299a676-81d2-40ce-94e6-0dbc4ef8e2db",
   "metadata": {},
   "source": [
    "#### **2. representing data feature using esm-2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6e43421-8322-4478-bd2f-2691f495d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c0a3955-21fb-4b12-944a-aa65602726cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load ESM-2 model\n",
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0320530-4db4-4af9-b411-82272a278753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "124\n",
      "('1afv_A', 'PIVQNLQGQMVHQAISPRTLNAWVKVVEEKAFSPEVIPMFSALSEGATPQDLNTMLNTVGGHQAAMQMLKETINEEAAEWDRLHPVHAGPIAPGQMREPRGSDIAGTTSTLQEQIGWMTHNPPIPVGEIYKRWIILGLNKIVRMYSPTSIL')\n"
     ]
    }
   ],
   "source": [
    "# 2. input data\n",
    "data_train_ab = list(zip(train_data.iloc[:, 0].astype(str) + '_' + train_data.iloc[:, 1].astype(str), train_data.iloc[:, 2].astype(str)))\n",
    "data_train_ag = list(zip(train_data.iloc[:, 0].astype(str) + '_' + train_data.iloc[:, 3].astype(str), train_data.iloc[:, 4].astype(str)))\n",
    "\n",
    "# data_train = data_train_ab + data_train_ag\n",
    "data_train = data_train_ag\n",
    "\n",
    "print(type(data_train))\n",
    "print(len(data_train))\n",
    "print(data_train[0])\n",
    "\n",
    "df = pd.DataFrame(data_train, columns=['protein_name', 'seq'])\n",
    "df.to_csv('/data/databases/epitope_prediction/sab/esm-rep-data_ag.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e16a4dd-0565-483c-b80d-fcf7cd6e4f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract per-residue representations fro each seq\n",
    "representations_list = []\n",
    "for i in range(len(data_train)):\n",
    "    data = [data_train[i]]\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "    batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "\n",
    "    # Extract per-residue representations (on CPU) \n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "    token_representations = results[\"representations\"][33]\n",
    "    representations_list.append(token_representations[0][1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72e95cd9-87ee-42e8-8234-23c419856425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the max length of protein seq is:  624\n",
      "successfully save the representation data of antigen sequences!\n"
     ]
    }
   ],
   "source": [
    "# save representations data\n",
    "max_cols = max([tensor.size(0) for tensor in representations_list])\n",
    "print('the max length of protein seq is: ', max_cols)\n",
    "for i, tensor in enumerate(representations_list):\n",
    "    if tensor.size(0) < max_cols:\n",
    "        padding = torch.zeros(max_cols - tensor.size(0), tensor.size(1))\n",
    "        representations_list[i] = torch.cat([tensor, padding], dim=0)\n",
    "    \n",
    "representations_tensor = torch.stack(representations_list)\n",
    "\n",
    "torch.save(representations_tensor, './data/traindata_esm_ag.pt')\n",
    "print('successfully save the representation data of antigen sequences!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e480afa4-7736-48fc-9742-69597fd23b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract per-residue representations fro each seq\n",
    "representations_list = []\n",
    "for i in range(len(data_train_ab)):\n",
    "    data = [data_train_ab[i]]\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "    batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "\n",
    "    # Extract per-residue representations (on CPU) \n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "    token_representations = results[\"representations\"][33]\n",
    "    representations_list.append(token_representations[0][1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cf123fe-e332-4e75-b2fb-63045bdc67be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the max length of protein seq is:  251\n",
      "successfully save the representation data of antibody sequences!\n"
     ]
    }
   ],
   "source": [
    "# save representations data\n",
    "max_cols = max([tensor.size(0) for tensor in representations_list])\n",
    "for i, tensor in enumerate(representations_list):\n",
    "    if tensor.size(0) < max_cols:\n",
    "        padding = torch.zeros(max_cols - tensor.size(0), tensor.size(1))\n",
    "        representations_list[i] = torch.cat([tensor, padding], dim=0)\n",
    "    \n",
    "\n",
    "representations_tensor = torch.stack(representations_list)\n",
    "\n",
    "torch.save(representations_tensor, './data/traindata_esm_ab.pt')\n",
    "print('successfully save the representation data of antibody sequences!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
